{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c7dd6b-359a-4147-ac5d-56aac9216be4",
   "metadata": {},
   "source": [
    "# Projet SAM -> Classifieur de genre musical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef234cc7-62cc-4ff3-941e-7246660e1cda",
   "metadata": {},
   "source": [
    "## Late Fusion (Text, Audio, Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4610a47a-163e-4c42-aa4e-8411c8bb8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import cv2\n",
    "import imutils\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728fee0-1d7e-4db7-b71e-ec4179d744a6",
   "metadata": {},
   "source": [
    "### Codify Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dfef76-74cb-4639-b7e2-2f241e2533ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_list():\n",
    "    df = pd.read_csv('./msdi/'+'labels.csv', header=None)\n",
    "    label_list = list(df.iloc[:, 0])\n",
    "    labels = {label_list[i]:i for i in range (0,len(label_list))} # Dictionary Etiquetes Possibles\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfac302-b965-45ff-9979-e67e8d9766f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blues': 0, 'Country': 1, 'Electronic': 2, 'Folk': 3, 'Jazz': 4, 'Latin': 5, 'Metal': 6, 'New Age': 7, 'Pop': 8, 'Punk': 9, 'Rap': 10, 'Reggae': 11, 'RnB': 12, 'Rock': 13, 'World': 14}\n"
     ]
    }
   ],
   "source": [
    "labels = get_label_list()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073359a9-b1dd-416b-8986-c10d3867e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_through(entries,labels):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(entries)):\n",
    "        \n",
    "        entry = entries.iloc[i,:]\n",
    "        x = entry[4:len(entry)]\n",
    "        \n",
    "        y = labels[entry[\"genre\"]]\n",
    "        \n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d459f-c1ed-40df-90f9-21ebd70aff50",
   "metadata": {},
   "source": [
    "## Load Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e444e1d7-07ef-40fe-b18e-99a081e320a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv('./msdi/mxm/joint_mxm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744f59e0-24ac-4919-84a1-042aa408872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = text_data[text_data['set'] == \"train\"]\n",
    "validation_text = text_data[text_data['set'] == \"val\"]\n",
    "test_text = text_data[text_data['set'] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bd4a70-afff-47b2-9874-bf6def6f3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text, y_train_text = read_through(train_text,labels)\n",
    "x_test_text, y_test_text = read_through(test_text,labels)\n",
    "x_validation_text, y_validation_text = read_through(validation_text,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e305784b-250c-4171-98e5-032a11cda865",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = np.asarray(x_train_text, dtype=np.float32)\n",
    "x_validation_text = np.asarray(x_validation_text, dtype=np.float32)\n",
    "x_test_text = np.asarray(x_test_text, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcca2526-9181-47d7-bfaf-7a74e365003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9260"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e96b542-1787-4b52-bb36-ab3fb604d8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9260"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76401389-ffec-4e36-ad9e-698f12d82407",
   "metadata": {},
   "source": [
    "### Classify Text and fetch predicted labels with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe7cd76-a004-4edb-accd-ec22cb37c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47b03333-192f-49b2-90df-7a4b555541bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "neigh.fit(x_train_text, y_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb2b61-52db-405e-9828-d0584adc7344",
   "metadata": {},
   "source": [
    "#### Predicted Labels by KNN (for late fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb3def6-e202-4f94-91a7-288c3a52e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_accu = neigh.score(x_test_text,y_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9fa3c7e-06b2-403e-999f-0b04b15ec4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3021164021164021"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "121f1f81-e267-4bbd-93da-c4d92a4f226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pred = neigh.predict(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b8ac7b6-4441-4412-b32e-345d1b534984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47610151-8d20-4be0-abaa-6ea58b32c177",
   "metadata": {},
   "source": [
    "## Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "801675b9-708b-49ef-877f-e9a6538b5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = pd.read_csv('./msdi/mxm/joint_hog_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c406276-49cc-48cd-a5ff-f04ca755dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = img_data[img_data['set'] == \"train\"]\n",
    "validation_img = img_data[img_data['set'] == \"val\"]\n",
    "test_img = img_data[img_data['set'] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf11bf92-a778-4582-95d2-af2950e27daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_img, y_train_img = read_through(train_img,labels)\n",
    "x_test_img, y_test_img = read_through(test_img,labels)\n",
    "x_validation_img, y_validation = read_through(validation_img,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ab8230-01b1-4539-8f0c-ec796da99b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_img = np.asarray(x_train_img, dtype=np.float32)\n",
    "x_validation_img = np.asarray(x_validation_img, dtype=np.float32)\n",
    "x_test_img = np.asarray(x_test_img, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e96cf264-c4bd-485d-9b6d-e097d762eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9260"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "086839c6-22c0-4f4d-be4a-8ddda0cc63ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9260"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f57638-4473-4fa1-ae8f-9ceb04405945",
   "metadata": {},
   "source": [
    "### Classify Images and fetch predicted labels with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5490e1aa-4106-4880-81f7-852da4cb72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd887fdb-4010-4e9f-8e39-6ec571bfdb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raiss\\Anaconda3\\envs\\SAM\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x_train_img, y_train_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8a335-27f2-4eff-8958-e2b79bd52604",
   "metadata": {},
   "source": [
    "#### Predicted Labels by Logistic Regression (for late fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53c1d559-6597-4da0-bf70-549c144a25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_accu = clf.score(x_test_img,y_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92968477-5573-45c8-b1b3-bb94786652e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15925925925925927"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b97ae02f-27fd-446e-9362-c81cd4298830",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = neigh.predict(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebd69586-ae88-4e36-80d3-2290d0cd6067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca800c8d-1b6c-4ce8-b17d-662e993afd17",
   "metadata": {},
   "source": [
    "## Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2a161d3-e9b0-49bf-bca7-8b927f4718ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = pd.read_csv('./msdi/mxm/joint_mfcc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13a061a9-886d-41f2-b1cd-538cbeb56945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio = audio_data[audio_data['set'] == \"train\"]\n",
    "validation_audio = audio_data[audio_data['set'] == \"val\"]\n",
    "test_audio = audio_data[audio_data['set'] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baf14c39-93e2-4634-a181-6ddbc55ba765",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_audio, y_train_audio = read_through(train_audio,labels)\n",
    "x_test_audio, y_test_audio = read_through(test_audio,labels)\n",
    "x_validation_audio, y_validation_audio = read_through(validation_audio,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35142271-978d-451c-b90c-ad39851326fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_audio = np.array(x_train_audio)\n",
    "x_validation_audio = np.array(x_validation_audio)\n",
    "x_test_audio = np.array(x_test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b08a7c-b299-419b-bbfb-db61d2dc2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_audio = np.array(y_train_audio)\n",
    "y_validation_audio = np.array(y_validation_audio)\n",
    "y_test_audio = np.array(y_test_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7fb41-ef5e-44fc-b206-78f4f1a97319",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a3a4cde-128d-40e6-98e5-a0003f088260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95cd8d75-921d-47b4-98b7-38f3808bf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = keras.Sequential([\n",
    "\n",
    "        # input layer\n",
    "        keras.layers.Flatten(input_shape=(6000,)),\n",
    "\n",
    "        # 1st dense layer\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "        # 2nd dense layer\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "        # 3rd dense layer\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(15, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5052ec1-9de1-4437-88d1-e7feb1fb056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = Adam(learning_rate=0.0001)\n",
    "model_cnn.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7445927-20d7-4b69-8f60-77d2cbd0edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_cnn.fit(x_train_audio, y_train_audio, validation_data=(x_validation_audio, y_validation_audio), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb278d-3a54-4b49-bff6-b26bc1d957db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(x) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430be1e2-f5eb-41b1-b5e6-54b4a970259b",
   "metadata": {},
   "source": [
    "## Late Fusion (text_pred, img_pred, audio_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "427bfcc6-5667-4e9c-9bf4-4774dae76741",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [text_pred, img_pred,audio_pred]\n",
    "accus = [text_accu, img_accu,audio_accu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5ae7bf1-cd4e-494e-85c8-f13d220cc479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84b252d4-8bc5-4798-bc1a-71b5d48af088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 4, 3]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e321f395-7336-4670-93a5-b940696bdea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_pred = []\n",
    "for i in range(len(img_pred)):\n",
    "    y = [predictions[j][i] for j in range(len(predictions))]\n",
    "    set_y = set(y)\n",
    "    if (len(set_y) == len(y)):\n",
    "        y = y[accus.index(max(accus))]\n",
    "    else:\n",
    "        y = max(set_y, key=y.count)\n",
    "    fusion_pred.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71b1b5b6-c60f-402f-acc3-77dbe6d183fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 6, 7]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d4633-ff80-434b-8617-745ccf2be9ec",
   "metadata": {},
   "source": [
    "### Late Fusion Acuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6231c26-985e-4539-9b2b-ce28f1777350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_text, fusion_pred) # y_test_text , y_test_img and y_test_audio are actually the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9d763-171a-418d-b524-3f6dbdb04248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0252082-0c44-4602-95bd-be73e6ba7aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
